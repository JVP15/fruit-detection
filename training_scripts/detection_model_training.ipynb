{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training the Detection Model\n",
    "\n",
    "This notebook lets us train and fine-tune the Yolo-v5 model for the detection and classification for DeepFruitVision. All of the training and preparation is taken care of in other Python scripts, so this is just a centralized place to run the training and fine-tuning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os # we need this to change the working directory quite a lot\n",
    "from modules.datasets import EnsembleDataset, save_dataset\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the dataset ready."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.chdir(os.path.join('..', 'modules'))\n",
    "\n",
    "fine_tune_dir = os.path.join('..', 'dataset', 'yolov5_fine_tune')\n",
    "fine_tune_val_dir = os.path.join(fine_tune_dir, 'val')\n",
    "fine_tune_label_dir = os.path.join(fine_tune_dir, 'labels')\n",
    "fine_tune_image_dir = os.path.join(fine_tune_dir, 'images')\n",
    "fine_tune_val_image_dir = os.path.join(fine_tune_val_dir, 'images')\n",
    "fine_tune_val_label_dir = os.path.join(fine_tune_val_dir, 'labels')\n",
    "\n",
    "os.makedirs(fine_tune_label_dir, exist_ok=True)\n",
    "os.makedirs(fine_tune_image_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(fine_tune_val_label_dir, exist_ok=True)\n",
    "os.makedirs(fine_tune_val_image_dir, exist_ok=True)\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "num_fine_tune_samples = 50\n",
    "experiment_index = 5 # YOU NEED TO CHANGE THIS BASED ON NUMBER OF 'EXPS' ARE IN THE TRAIN FOLDER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ensemble_dataset = EnsembleDataset(for_yolov5=True)\n",
    "\n",
    "random_indices = np.random.permutation(len(ensemble_dataset))\n",
    "fine_tune_indices = random_indices[:num_fine_tune_samples]\n",
    "val_indices = random_indices[num_fine_tune_samples:]\n",
    "\n",
    "fine_tune_dataset = Subset(ensemble_dataset, fine_tune_indices)\n",
    "val_dataset = Subset(ensemble_dataset, val_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the ensemble (used for fine tuning) and overall datasets to the disk for Yolo-v5 training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving dataset to ..\\dataset\\yolov5_fine_tune\\images and ..\\dataset\\yolov5_fine_tune\\labels: 100%|██████████| 50/50 [00:00<00:00, 145.10it/s]\n",
      "Saving dataset to ..\\dataset\\yolov5_fine_tune\\val\\images and ..\\dataset\\yolov5_fine_tune\\val\\labels: 100%|██████████| 105/105 [00:00<00:00, 143.87it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dataset(fine_tune_dataset, fine_tune_image_dir, fine_tune_label_dir)\n",
    "save_dataset(val_dataset, fine_tune_val_image_dir, fine_tune_val_label_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting dataset: 100%|██████████| 6331/6331 [03:02<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: 4000 training objects, 1053 validation objects, 29895 testing objects\n",
      "papaya: 1201 training objects, 305 validation objects, 383 testing objects\n",
      "mango: 4000 training objects, 1005 validation objects, 17341 testing objects\n",
      "487 empty images in training set, 132 empty images in validation set, 69 empty images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving dataset to ..\\dataset\\images\\train and ..\\dataset\\labels\\train: 100%|██████████| 1432/1432 [00:13<00:00, 105.27it/s]\n",
      "Saving dataset to ..\\dataset\\images\\val and ..\\dataset\\labels\\val: 100%|██████████| 371/371 [00:03<00:00, 108.94it/s]\n",
      "Saving dataset to ..\\dataset\\images\\test and ..\\dataset\\labels\\test: 100%|██████████| 4528/4528 [00:58<00:00, 77.07it/s] \n"
     ]
    }
   ],
   "source": [
    "%run datasets.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the Yolo-v5 model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.join('..', 'yolov5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjvp15\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=, data=../apple_papaya_mango.yaml, hyp=data/hyps/hyp.scratch-high.yaml, epochs=40, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m YOLOv5 is out of date by 1 commit. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5  2022-11-21 Python-3.10.5 torch-1.12.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.21"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\yolov5\\wandb\\run-20221122_112837-3i3ovgct</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/jvp15/train/runs/3i3ovgct\" target=\"_blank\">expert-sun-99</a></strong> to <a href=\"https://wandb.ai/jvp15/train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\train... 1432 images, 487 backgrounds, 3 corrupt: 100%|██████████| 1432/1432 00:09\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\train\\image_282.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0092]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\train\\image_467.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0064]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\train\\image_789.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0143]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\train.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\val... 371 images, 132 backgrounds, 0 corrupt: 100%|██████████| 371/371 00:09\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\val.cache\n",
      "\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m5.21 anchors/target, 0.995 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp5\\labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mruns\\train\\exp5\u001B[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/39      1.49G     0.1122     0.0315    0.02212        104        416: 100%|██████████| 90/90 00:21\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:06\n",
      "                   all        371       2363      0.226      0.161      0.149     0.0465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/39      2.22G    0.08216    0.02974    0.01763         39        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:04\n",
      "                   all        371       2363      0.487      0.468      0.471      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/39      2.22G    0.07435    0.02622    0.01242         39        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.424      0.536      0.487      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/39      2.22G    0.06955    0.02586   0.008518         41        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:04\n",
      "                   all        371       2363      0.755      0.653      0.719      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/39      2.22G    0.06414    0.02595   0.006295         55        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.649      0.625      0.638      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/39      2.22G    0.06166    0.02411   0.004784         34        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.791      0.681      0.755      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/39      2.22G    0.05848    0.02444   0.003956         62        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.771      0.676      0.761      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/39      2.22G    0.05723    0.02377   0.003618         55        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.786      0.712      0.783      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/39      2.22G    0.05626    0.02502   0.003259        117        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.805      0.724      0.803      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/39      2.22G    0.05461    0.02428   0.002616         48        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363       0.76      0.739      0.782      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/39      2.22G    0.05288      0.023   0.002538         81        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363        0.8      0.748      0.824      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/39      2.22G    0.05263    0.02351   0.002502         81        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.838      0.777      0.853      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/39      2.22G    0.05336    0.02366   0.002656         23        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.866      0.762      0.857      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/39      2.22G    0.05179    0.02373   0.002279         53        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.853      0.752      0.846      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/39      2.22G    0.05031     0.0219   0.002086         87        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.853      0.777      0.859      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/39      2.22G    0.05157    0.02241   0.002145        113        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.852      0.765      0.851      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/39      2.22G    0.04965    0.02302   0.002305         42        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.846      0.773      0.855      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/39      2.22G    0.04896    0.02246    0.00182         64        416: 100%|██████████| 90/90 00:17\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.819      0.785      0.852      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/39      2.22G    0.04851    0.02292   0.002024         79        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.859      0.779      0.867      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/39      2.22G     0.0484    0.02276   0.001674        108        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.849       0.78      0.868       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/39      2.22G    0.04839    0.02243   0.001865         51        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.864      0.772      0.866      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/39      2.22G    0.04799    0.02209    0.00163         56        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363       0.88      0.762      0.868      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/39      2.22G    0.04655    0.02211   0.001904         65        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.868      0.775      0.874      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/39      2.22G    0.04593    0.02221   0.001475         48        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.852      0.791      0.873      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/39      2.22G    0.04629    0.02144   0.001638         70        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.889      0.756      0.877      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/39      2.22G    0.04669    0.02173   0.001432         49        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.861      0.789      0.873       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/39      2.22G    0.04574    0.02148   0.001348         19        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.863      0.806      0.892      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/39      2.22G    0.04524    0.02172   0.001385         12        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.877       0.79      0.887      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/39      2.22G    0.04456    0.02172   0.001334         75        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.878      0.796      0.886      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/39      2.22G    0.04502    0.02124   0.001298         47        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.859      0.808      0.891      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/39      2.22G    0.04489    0.02293   0.001308        107        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.857      0.824       0.89      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/39      2.22G    0.04398    0.02121   0.001118         86        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.871      0.782      0.878      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/39      2.22G    0.04414    0.02069   0.001166         35        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.877      0.798      0.887      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/39      2.22G     0.0442    0.02043   0.001003         23        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363       0.89      0.803      0.894      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/39      2.22G    0.04381    0.02068   0.001148        101        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.865      0.807      0.894      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/39      2.22G    0.04362    0.02102    0.00117         69        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363       0.87      0.794      0.887      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/39      2.22G    0.04419    0.02104   0.001104         65        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.861      0.818      0.891      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/39      2.22G    0.04375    0.02074   0.001175         11        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.844      0.833      0.895      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/39      2.22G    0.04217    0.02033  0.0008425         85        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:02\n",
      "                   all        371       2363      0.868      0.808      0.892      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/39      2.22G    0.04306    0.02003  0.0009027         32        416: 100%|██████████| 90/90 00:18\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:03\n",
      "                   all        371       2363      0.872      0.803      0.899      0.565\n",
      "\n",
      "40 epochs completed in 0.244 hours.\n",
      "Optimizer stripped from runs\\train\\exp5\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\exp5\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating runs\\train\\exp5\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 12/12 00:05\n",
      "                   all        371       2363      0.871      0.804      0.899      0.564\n",
      "                 apple        371       1053       0.86       0.67      0.809      0.419\n",
      "                papaya        371        305      0.862      0.799      0.913      0.619\n",
      "                 mango        371       1005      0.891      0.942      0.976      0.655\n",
      "Results saved to \u001B[1mruns\\train\\exp5\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='47.257 MB of 48.592 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9725…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fff3c805f8e24506930517ed2a679a25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▁▄▄▆▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▁▃▃▅▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>metrics/precision</td><td>▁▄▃▇▅▇▇▇▇▇▇▇█████▇██████████████████████</td></tr><tr><td>metrics/recall</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██████▇████████</td></tr><tr><td>train/box_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▇▅▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/obj_loss</td><td>█▇▅▅▅▃▄▃▄▄▃▃▃▃▂▂▃▂▃▃▂▂▂▂▂▂▂▂▂▂▃▂▁▁▁▂▂▁▁▁</td></tr><tr><td>val/box_loss</td><td>█▅▅▃▃▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/cls_loss</td><td>█▆▄▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/obj_loss</td><td>█▅▄▄▃▄▃▂▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>x/lr0</td><td>█▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>x/lr1</td><td>▃▅████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>x/lr2</td><td>▃▅████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best/epoch</td><td>39</td></tr><tr><td>best/mAP_0.5</td><td>0.89928</td></tr><tr><td>best/mAP_0.5:0.95</td><td>0.56453</td></tr><tr><td>best/precision</td><td>0.87193</td></tr><tr><td>best/recall</td><td>0.80258</td></tr><tr><td>metrics/mAP_0.5</td><td>0.89927</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.56447</td></tr><tr><td>metrics/precision</td><td>0.87106</td></tr><tr><td>metrics/recall</td><td>0.8038</td></tr><tr><td>train/box_loss</td><td>0.04306</td></tr><tr><td>train/cls_loss</td><td>0.0009</td></tr><tr><td>train/obj_loss</td><td>0.02003</td></tr><tr><td>val/box_loss</td><td>0.03181</td></tr><tr><td>val/cls_loss</td><td>0.00022</td></tr><tr><td>val/obj_loss</td><td>0.0162</td></tr><tr><td>x/lr0</td><td>0.00145</td></tr><tr><td>x/lr1</td><td>0.00145</td></tr><tr><td>x/lr2</td><td>0.00145</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">expert-sun-99</strong>: <a href=\"https://wandb.ai/jvp15/train/runs/3i3ovgct\" target=\"_blank\">https://wandb.ai/jvp15/train/runs/3i3ovgct</a><br/>Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20221122_112837-3i3ovgct\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --data ../apple_papaya_mango.yaml --weights yolov5s.pt --img 416 --workers 4 --epochs 40 --hyp data/hyps/hyp.scratch-high.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's evaluate the model on the test dataset (which is much larger than the validation dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "best_weights = os.path.join('runs', 'train', 'exp' + str(experiment_index), 'weights', 'best.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mdata=../apple_papaya_mango.yaml, weights=['runs\\\\train\\\\exp5\\\\weights\\\\best.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.6, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs\\val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5  2022-11-21 Python-3.10.5 torch-1.12.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mScanning C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\test... 4528 images, 69 backgrounds, 24 corrupt: 100%|██████████| 4528/4528 01:13\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1279.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0044]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1376.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0031]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1431.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0144]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1640.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0013]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1696.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0108]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1924.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0123]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_197.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0005]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2296.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0078]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_244.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0061]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2501.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0194]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2688.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0195]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2981.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0123]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3031.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0084      1.0129]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_307.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0377]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_321.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0243]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3404.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0102]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3627.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0079]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3664.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0328]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3830.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0037]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3834.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0068]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3894.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0013]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_838.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0366]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_922.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0174]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_965.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mNew cache created: C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\test.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 141/141 00:55\n",
      "                   all       4504      47442       0.87      0.793      0.875      0.536\n",
      "                 apple       4504      29895      0.852      0.674      0.791      0.402\n",
      "                papaya       4504        383      0.856      0.774      0.864      0.552\n",
      "                 mango       4504      17164      0.901      0.932      0.969      0.655\n",
      "Speed: 0.1ms pre-process, 2.8ms inference, 1.3ms NMS per image at shape (32, 3, 416, 416)\n",
      "Results saved to \u001B[1mruns\\val\\exp27\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%run val.py --data ../apple_papaya_mango.yaml --weights {best_weights} --img 416 --task test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we fine-tune Yolo-v5 on the fine-tune dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjvp15\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=runs\\train\\exp5\\weights\\best.pt, cfg=, data=../fine_tune_apple_papaya_mango.yaml, hyp=data/hyps/hyp.scratch-high.yaml, epochs=40, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5  2022-11-21 Python-3.10.5 torch-1.12.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.21"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\yolov5\\wandb\\run-20221122_115240-1h67mo6n</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/jvp15/train/runs/1h67mo6n\" target=\"_blank\">ancient-deluge-101</a></strong> to <a href=\"https://wandb.ai/jvp15/train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from runs\\train\\exp5\\weights\\best.pt\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\yolov5_fine_tune\\labels.cache... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 00:00\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\yolov5_fine_tune\\val\\labels.cache... 105 images, 0 backgrounds, 0 corrupt: 100%|██████████| 105/105 00:00\n",
      "\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m5.73 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\exp6\\labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mruns\\train\\exp6\u001B[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/39      1.47G    0.04263    0.04356    0.04645          5        416: 100%|██████████| 4/4 00:03\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.197      0.492      0.249      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/39      1.99G     0.0431    0.03325    0.04618         15        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.307      0.474      0.298      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/39      1.99G    0.05108    0.03669    0.03601         15        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.366      0.587      0.392      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/39      1.99G    0.03945    0.03821    0.03079         24        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.484      0.586      0.496      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/39      1.99G     0.0394    0.02823    0.02786          6        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.535      0.594      0.564      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/39      1.99G    0.02998    0.02656    0.02573          6        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.591      0.643      0.646      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/39      1.99G    0.03496    0.02872    0.01856         21        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.631      0.702      0.727      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/39      1.99G    0.03248    0.02114    0.01953          8        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417       0.62      0.796      0.774      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/39      1.99G    0.04327    0.02801    0.01491          4        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.748      0.712      0.806      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/39      1.99G    0.03385    0.03006    0.01074         15        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.753      0.734      0.819      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/39      1.99G    0.03415    0.02804    0.01116         24        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.737      0.752      0.828      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/39      1.99G    0.03462    0.02357     0.0117          5        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.702      0.786      0.827      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/39      1.99G    0.03548    0.02374    0.01034         18        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.742       0.78      0.836      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/39      1.99G    0.03217    0.02409   0.009988          8        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.782      0.764       0.85      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/39      1.99G    0.03152    0.02502   0.007746         22        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.808      0.734      0.847      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/39      1.99G    0.03002    0.01986   0.009658          4        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.789      0.736       0.85      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/39      1.99G    0.04003    0.02724    0.01131         36        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.803      0.725      0.844       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/39      1.99G    0.03715     0.0286    0.01037          4        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.798      0.748      0.851      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/39      1.99G    0.03188    0.02507   0.007659         22        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.793      0.737      0.846      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/39      1.99G     0.0335    0.02493    0.01271         25        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.756      0.796      0.858       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/39      1.99G    0.03097     0.0227    0.00638         16        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.752       0.81      0.856      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/39      1.99G    0.03278    0.02261   0.007893         10        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.751      0.817      0.861      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/39      1.99G    0.04136    0.03588    0.01469         29        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.773      0.805      0.861      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/39      1.99G    0.03258    0.01952   0.007879          6        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.764       0.82      0.863      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/39      1.99G    0.03866    0.02634    0.00604         16        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.773      0.819      0.865      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/39      1.99G    0.03406    0.02474   0.007112         14        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.787      0.808      0.867      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/39      1.99G    0.03479     0.0232   0.009064          7        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.807        0.8      0.871      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/39      1.99G     0.0284    0.02132    0.00803          9        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.792      0.814       0.87       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/39      1.99G    0.03251    0.02656   0.006571         34        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.789      0.815      0.871      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/39      1.99G     0.0272    0.02575   0.004367         12        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417        0.8      0.815      0.872      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/39      1.99G    0.03383    0.02618   0.007953         35        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.772       0.82      0.859       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/39      1.99G    0.02946    0.02418   0.006946         29        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417      0.773      0.832      0.859      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/39      1.99G    0.03752    0.02931   0.006994         17        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.787      0.834      0.868      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/39      1.99G    0.02906    0.02697   0.004939         30        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.786      0.831      0.872      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/39      1.99G    0.03473    0.02975   0.005096         47        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417        0.8      0.827      0.877      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/39      1.99G    0.02833    0.02056   0.004094         12        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417       0.83       0.81      0.883      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/39      1.99G    0.03019    0.02942    0.00609         31        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.814      0.837       0.89      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/39      1.99G    0.03233    0.02203   0.009096         13        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.832      0.828      0.895       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/39      1.99G    0.03133    0.01946   0.004613         20        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:00\n",
      "                   all        105        417      0.845      0.813      0.898      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/39      1.99G    0.03597    0.02066   0.009001          8        416: 100%|██████████| 4/4 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:01\n",
      "                   all        105        417       0.85      0.815        0.9      0.666\n",
      "\n",
      "40 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs\\train\\exp6\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\exp6\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating runs\\train\\exp6\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 00:02\n",
      "                   all        105        417       0.85      0.816        0.9      0.666\n",
      "                 apple        105        202      0.865      0.918      0.936      0.741\n",
      "                papaya        105         81      0.842      0.723      0.871      0.544\n",
      "                 mango        105        134      0.842      0.806      0.894      0.713\n",
      "Results saved to \u001B[1mruns\\train\\exp6\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='44.851 MB of 46.106 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9727…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d77622f4b08541bcb6f0f03f20bc65ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▁▂▃▄▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▁▂▂▄▄▅▆▆▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇████████</td></tr><tr><td>metrics/precision</td><td>▁▂▃▄▅▅▆▆▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█████</td></tr><tr><td>metrics/recall</td><td>▁▁▃▃▃▄▅▇▆▆▆▇▇▇▆▆▆▆▆▇▇█▇██▇▇████████▇████</td></tr><tr><td>train/box_loss</td><td>▆▆█▅▅▂▃▃▆▃▃▃▃▂▂▂▅▄▂▃▂▃▅▃▄▃▃▁▃▁▃▂▄▂▃▁▂▃▂▄</td></tr><tr><td>train/cls_loss</td><td>██▆▅▅▅▃▄▃▂▂▂▂▂▂▂▂▂▂▂▁▂▃▂▁▁▂▂▁▁▂▁▁▁▁▁▁▂▁▂</td></tr><tr><td>train/obj_loss</td><td>█▅▆▆▄▃▄▁▃▄▃▂▂▂▃▁▃▄▃▃▂▂▆▁▃▃▂▂▃▃▃▂▄▃▄▁▄▂▁▁</td></tr><tr><td>val/box_loss</td><td>▆▅▆▄▄▅▄▇▃▄▄▃▃▂▃█▅▃▇▃▅▄▆▆▇▅▄▄▃▂▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val/cls_loss</td><td>█▇▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/obj_loss</td><td>█▇▇▇▆▇▇▇▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>x/lr0</td><td>██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>x/lr1</td><td>▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇▇▇██████████▇▇▇▆▆▅▅▅▄▄▄▃▃</td></tr><tr><td>x/lr2</td><td>▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇▇▇██████████▇▇▇▆▆▅▅▅▄▄▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best/epoch</td><td>39</td></tr><tr><td>best/mAP_0.5</td><td>0.90049</td></tr><tr><td>best/mAP_0.5:0.95</td><td>0.66623</td></tr><tr><td>best/precision</td><td>0.85018</td></tr><tr><td>best/recall</td><td>0.81503</td></tr><tr><td>metrics/mAP_0.5</td><td>0.90039</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.66587</td></tr><tr><td>metrics/precision</td><td>0.84965</td></tr><tr><td>metrics/recall</td><td>0.81571</td></tr><tr><td>train/box_loss</td><td>0.03597</td></tr><tr><td>train/cls_loss</td><td>0.009</td></tr><tr><td>train/obj_loss</td><td>0.02066</td></tr><tr><td>val/box_loss</td><td>0.0224</td></tr><tr><td>val/cls_loss</td><td>0.0039</td></tr><tr><td>val/obj_loss</td><td>0.01694</td></tr><tr><td>x/lr0</td><td>0.00145</td></tr><tr><td>x/lr1</td><td>0.00145</td></tr><tr><td>x/lr2</td><td>0.00145</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">ancient-deluge-101</strong>: <a href=\"https://wandb.ai/jvp15/train/runs/1h67mo6n\" target=\"_blank\">https://wandb.ai/jvp15/train/runs/1h67mo6n</a><br/>Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20221122_115240-1h67mo6n\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --data ../fine_tune_apple_papaya_mango.yaml --weights {best_weights} --img 416 --workers 4 --epochs 40 --hyp data/hyps/hyp.scratch-high.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And lastly, re-evaluate the model on the test dataset so that we know we didn't loose too much performance during fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "fine_tuned_weights = os.path.join('runs', 'train', 'exp' + str(experiment_index + 1), 'weights', 'best.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mdata=../apple_papaya_mango.yaml, weights=['runs\\\\train\\\\exp6\\\\weights\\\\best.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.6, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs\\val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5  2022-11-21 Python-3.10.5 torch-1.12.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mScanning C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\labels\\test.cache... 4528 images, 69 backgrounds, 24 corrupt: 100%|██████████| 4528/4528 00:00\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1279.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0044]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1376.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0031]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1431.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0144]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1640.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0013]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1696.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0108]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_1924.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0123]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_197.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0005]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2296.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0078]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_244.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0061]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2501.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0194]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2688.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0195]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_2981.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0123]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3031.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0084      1.0129]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_307.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0377]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_321.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0243]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3404.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0102]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3627.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0079]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3664.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0328]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3830.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0037]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3834.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0068]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_3894.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0013]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_838.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0366]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_922.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0174]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mWARNING  C:\\Users\\jorda\\Documents\\School\\CMPE 295\\fruit-detection\\dataset\\images\\test\\image_965.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 141/141 00:47\n",
      "                   all       4504      47442      0.802      0.643       0.73        0.4\n",
      "                 apple       4504      29895      0.745      0.493      0.598      0.276\n",
      "                papaya       4504        383      0.732      0.799      0.798      0.492\n",
      "                 mango       4504      17164      0.928      0.637      0.795      0.432\n",
      "Speed: 0.1ms pre-process, 2.7ms inference, 1.2ms NMS per image at shape (32, 3, 416, 416)\n",
      "Results saved to \u001B[1mruns\\val\\exp29\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%run val.py --data ../apple_papaya_mango.yaml --weights {fine_tuned_weights} --img 416 --task test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}